
[2020-02-08T22:53:18.360Z] Error: Could not read cluster from kubeconfig for context docker-for-desktop
    at new KubeApi (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at Function.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at processTicksAndRejections (internal/process/task_queues.js:93:5)
Error Details:
context: docker-for-desktop
config:
  clusters: []
  contexts: []
  users: []
  currentContext: docker-for-desktop


[2020-02-08T22:53:18.367Z] Error: Failed resolving one or more providers:
- local-kubernetes
    at Garden.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/garden.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/garden.js:0)
Error Details:
rawConfigs:
  - name: exec
  - name: container
  - name: local-kubernetes
    environments:
      - local
taskResults:
  resolve-provider.exec:
    type: resolve-provider
    key: resolve-provider.exec
    name: exec
    description: resolving provider exec
    completedAt: '2020-02-08T22:53:09.959Z'
    batchId: b61d62e9-9ec2-4d31-b760-a0d5fbd546b6
    output:
      name: exec
      dependencies: []
      moduleConfigs: []
      config:
        name: exec
        path: /home/brendan/git/rat-or-cat
      status:
        ready: true
        outputs: {}
    dependencyResults: {}
  resolve-provider.container:
    type: resolve-provider
    key: resolve-provider.container
    name: container
    description: resolving provider container
    completedAt: '2020-02-08T22:53:09.959Z'
    batchId: b61d62e9-9ec2-4d31-b760-a0d5fbd546b6
    output:
      name: container
      dependencies: []
      moduleConfigs: []
      config:
        name: container
        path: /home/brendan/git/rat-or-cat
      status:
        ready: true
        outputs: {}
    dependencyResults: {}
  resolve-provider.local-kubernetes:
    type: resolve-provider
    description: resolving provider local-kubernetes
    key: resolve-provider.local-kubernetes
    name: local-kubernetes
    error:
      detail:
        context: docker-for-desktop
        config:
          clusters: []
          contexts: []
          users: []
          currentContext: docker-for-desktop
      type: configuration
    completedAt: '2020-02-08T22:53:18.356Z'
    batchId: b61d62e9-9ec2-4d31-b760-a0d5fbd546b6
messages:
  - >-
    - local-kubernetes: Could not read cluster from kubeconfig for context
    docker-for-desktop


[2020-02-08T22:53:37.121Z] Error: Could not read cluster from kubeconfig for context docker-for-desktop
    at new KubeApi (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at Function.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at processTicksAndRejections (internal/process/task_queues.js:93:5)
Error Details:
context: docker-for-desktop
config:
  clusters: []
  contexts: []
  users: []
  currentContext: docker-for-desktop


[2020-02-08T22:53:37.126Z] Error: Failed resolving one or more providers:
- local-kubernetes
    at Garden.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/garden.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/garden.js:0)
Error Details:
rawConfigs:
  - name: exec
  - name: container
  - name: local-kubernetes
    environments:
      - local
taskResults:
  resolve-provider.exec:
    type: resolve-provider
    key: resolve-provider.exec
    name: exec
    description: resolving provider exec
    completedAt: '2020-02-08T22:53:37.019Z'
    batchId: 802c7e41-2712-4c35-977c-7104e10eb0fc
    output:
      name: exec
      dependencies: []
      moduleConfigs: []
      config:
        name: exec
        path: /home/brendan/git/rat-or-cat
      status:
        ready: true
        outputs: {}
    dependencyResults: {}
  resolve-provider.container:
    type: resolve-provider
    key: resolve-provider.container
    name: container
    description: resolving provider container
    completedAt: '2020-02-08T22:53:37.019Z'
    batchId: 802c7e41-2712-4c35-977c-7104e10eb0fc
    output:
      name: container
      dependencies: []
      moduleConfigs: []
      config:
        name: container
        path: /home/brendan/git/rat-or-cat
      status:
        ready: true
        outputs: {}
    dependencyResults: {}
  resolve-provider.local-kubernetes:
    type: resolve-provider
    description: resolving provider local-kubernetes
    key: resolve-provider.local-kubernetes
    name: local-kubernetes
    error:
      detail:
        context: docker-for-desktop
        config:
          clusters: []
          contexts: []
          users: []
          currentContext: docker-for-desktop
      type: configuration
    completedAt: '2020-02-08T22:53:37.116Z'
    batchId: 802c7e41-2712-4c35-977c-7104e10eb0fc
messages:
  - >-
    - local-kubernetes: Could not read cluster from kubeconfig for context
    docker-for-desktop


[2020-02-08T23:01:03.704Z] Error: Could not read cluster from kubeconfig for context docker-for-desktop
    at new KubeApi (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at Function.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/api.js:0)
    at processTicksAndRejections (internal/process/task_queues.js:93:5)
Error Details:
context: docker-for-desktop
config:
  clusters: []
  contexts: []
  users: []
  currentContext: docker-for-desktop


[2020-02-08T23:01:03.712Z] Error: Failed resolving one or more providers:
- local-kubernetes
    at Garden.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/garden.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/garden.js:0)
Error Details:
rawConfigs:
  - name: exec
  - name: container
  - name: local-kubernetes
    environments:
      - local
taskResults:
  resolve-provider.exec:
    type: resolve-provider
    key: resolve-provider.exec
    name: exec
    description: resolving provider exec
    completedAt: '2020-02-08T23:01:03.522Z'
    batchId: b096fddf-d738-483c-b43c-6a9986fb40f2
    output:
      name: exec
      dependencies: []
      moduleConfigs: []
      config:
        name: exec
        path: /home/brendan/git/rat-or-cat
      status:
        ready: true
        outputs: {}
    dependencyResults: {}
  resolve-provider.container:
    type: resolve-provider
    key: resolve-provider.container
    name: container
    description: resolving provider container
    completedAt: '2020-02-08T23:01:03.522Z'
    batchId: b096fddf-d738-483c-b43c-6a9986fb40f2
    output:
      name: container
      dependencies: []
      moduleConfigs: []
      config:
        name: container
        path: /home/brendan/git/rat-or-cat
      status:
        ready: true
        outputs: {}
    dependencyResults: {}
  resolve-provider.local-kubernetes:
    type: resolve-provider
    description: resolving provider local-kubernetes
    key: resolve-provider.local-kubernetes
    name: local-kubernetes
    error:
      detail:
        context: docker-for-desktop
        config:
          clusters: []
          contexts: []
          users: []
          currentContext: docker-for-desktop
      type: configuration
    completedAt: '2020-02-08T23:01:03.699Z'
    batchId: b096fddf-d738-483c-b43c-6a9986fb40f2
messages:
  - >-
    - local-kubernetes: Could not read cluster from kubeconfig for context
    docker-for-desktop


[2020-02-09T08:50:27.547Z] Error: Unable to get microk8s status. Is the cluster installed and running?
    at Object.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/local/microk8s.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/plugins/kubernetes/local/microk8s.js:0)
    at processTicksAndRejections (internal/process/task_queues.js:93:5)
Error Details:
status: ''


[2020-02-09T08:50:27.558Z] Error: Failed resolving one or more providers:
- local-kubernetes
    at Garden.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/garden.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/garden.js:0)
Error Details:
rawConfigs:
  - name: exec
  - name: container
  - name: local-kubernetes
    environments:
      - local
taskResults:
  resolve-provider.exec:
    type: resolve-provider
    key: resolve-provider.exec
    name: exec
    description: resolving provider exec
    completedAt: '2020-02-09T08:50:05.451Z'
    batchId: bb24814e-a1c2-4412-a1cd-3e00b1e69c2d
    output:
      name: exec
      dependencies: []
      moduleConfigs: []
      config:
        name: exec
        path: /home/brendan/git/rat_or_cat
      status:
        ready: true
        outputs: {}
    dependencyResults: {}
  resolve-provider.container:
    type: resolve-provider
    key: resolve-provider.container
    name: container
    description: resolving provider container
    completedAt: '2020-02-09T08:50:05.451Z'
    batchId: bb24814e-a1c2-4412-a1cd-3e00b1e69c2d
    output:
      name: container
      dependencies: []
      moduleConfigs: []
      config:
        name: container
        path: /home/brendan/git/rat_or_cat
      status:
        ready: true
        outputs: {}
    dependencyResults: {}
  resolve-provider.local-kubernetes:
    type: resolve-provider
    description: resolving provider local-kubernetes
    key: resolve-provider.local-kubernetes
    name: local-kubernetes
    error:
      detail:
        status: ''
      type: runtime
    completedAt: '2020-02-09T08:50:27.527Z'
    batchId: bb24814e-a1c2-4412-a1cd-3e00b1e69c2d
messages:
  - >-
    - local-kubernetes: Unable to get microk8s status. Is the cluster installed
    and running?


[2020-02-09T09:17:20.069Z] Error: Service frontend has no active ingresses
    at CallCommand.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/commands/call.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/commands/call.js:0)
Error Details:
serviceName: frontend
serviceStatus:
  forwardablePorts:
    - name: http
      protocol: TCP
      targetPort: 80
  ingresses: []
  state: outdated
  detail:
    remoteResources:
      - kind: Deployment
        apiVersion: apps/v1
        metadata:
          name: frontend-v-fa70afb9b6
          namespace: rat-or-cat
          selfLink: >-
            /apis/apps/v1/namespaces/rat-or-cat/deployments/frontend-v-fa70afb9b6
          uid: e527877f-ce9a-497e-9df6-741cb1e37798
          resourceVersion: '5724985'
          generation: 1
          creationTimestamp: '2020-02-09T09:16:34Z'
          labels:
            garden.io/version: v-fa70afb9b6
            module: frontend
            service: frontend
          annotations:
            deployment.kubernetes.io/revision: '1'
            garden.io/configured.replicas: '1'
            garden.io/generated: 'true'
            garden.io/manifest-hash: 0d1f0b8456958dd41e689edab0d6c6a42f8163b0b556bda7c906a7a3ba1dcb5a
            garden.io/version: v-fa70afb9b6
            kubectl.kubernetes.io/last-applied-configuration: >
              {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{"garden.io/configured.replicas":"1","garden.io/generated":"true","garden.io/manifest-hash":"0d1f0b8456958dd41e689edab0d6c6a42f8163b0b556bda7c906a7a3ba1dcb5a","garden.io/version":"v-fa70afb9b6"},"labels":{"garden.io/version":"v-fa70afb9b6","module":"frontend","service":"frontend"},"name":"frontend-v-fa70afb9b6","namespace":"rat-or-cat"},"spec":{"replicas":1,"revisionHistoryLimit":3,"selector":{"matchLabels":{"garden.io/version":"v-fa70afb9b6","service":"frontend"}},"strategy":{"rollingUpdate":{"maxSurge":1,"maxUnavailable":1},"type":"RollingUpdate"},"template":{"metadata":{"labels":{"garden.io/version":"v-fa70afb9b6","module":"frontend","service":"frontend"}},"spec":{"containers":[{"env":[{"name":"GARDEN_VERSION","value":"v-fa70afb9b6"},{"name":"GARDEN_MODULE_FRONTEND__OUTPUT_LOCAL_IMAGE_NAME","value":"frontend"},{"name":"GARDEN_MODULE_FRONTEND__OUTPUT_DEPLOYMENT_IMAGE_NAME","value":"localhost:32000/rat-or-cat/frontend"},{"name":"GARDEN_DEPENDENCIES","value":"[{\"moduleName\":\"frontend\",\"name\":\"frontend\",\"outputs\":{\"local-image-name\":\"frontend\",\"deployment-image-name\":\"localhost:32000/rat-or-cat/frontend\"},\"type\":\"build\",\"version\":\"v-fa70afb9b6\"}]"},{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"POD_SERVICE_ACCOUNT","valueFrom":{"fieldRef":{"fieldPath":"spec.serviceAccountName"}}}],"image":"localhost:32000/rat-or-cat/frontend:v-fa70afb9b6","imagePullPolicy":"IfNotPresent","name":"frontend","ports":[{"containerPort":80,"name":"http","protocol":"TCP"}],"resources":{"limits":{"cpu":"1","memory":"1Gi"},"requests":{"cpu":"10m","memory":"64Mi"}},"securityContext":{"allowPrivilegeEscalation":false}}],"dnsPolicy":"ClusterFirst","restartPolicy":"Always","terminationGracePeriodSeconds":5}}}}
        spec:
          replicas: 1
          selector:
            matchLabels:
              garden.io/version: v-fa70afb9b6
              service: frontend
          template:
            metadata:
              creationTimestamp: null
              labels:
                garden.io/version: v-fa70afb9b6
                module: frontend
                service: frontend
            spec:
              containers:
                - name: frontend
                  image: 'localhost:32000/rat-or-cat/frontend:v-fa70afb9b6'
                  ports:
                    - name: http
                      containerPort: 80
                      protocol: TCP
                  env:
                    - name: GARDEN_VERSION
                      value: v-fa70afb9b6
                    - name: GARDEN_MODULE_FRONTEND__OUTPUT_LOCAL_IMAGE_NAME
                      value: frontend
                    - name: GARDEN_MODULE_FRONTEND__OUTPUT_DEPLOYMENT_IMAGE_NAME
                      value: 'localhost:32000/rat-or-cat/frontend'
                    - name: GARDEN_DEPENDENCIES
                      value: >-
                        [{"moduleName":"frontend","name":"frontend","outputs":{"local-image-name":"frontend","deployment-image-name":"localhost:32000/rat-or-cat/frontend"},"type":"build","version":"v-fa70afb9b6"}]
                    - name: POD_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.name
                    - name: POD_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: POD_IP
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: status.podIP
                    - name: POD_SERVICE_ACCOUNT
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.serviceAccountName
                  resources:
                    limits:
                      cpu: '1'
                      memory: 1Gi
                    requests:
                      cpu: 10m
                      memory: 64Mi
                  terminationMessagePath: /dev/termination-log
                  terminationMessagePolicy: File
                  imagePullPolicy: IfNotPresent
                  securityContext:
                    allowPrivilegeEscalation: false
              restartPolicy: Always
              terminationGracePeriodSeconds: 5
              dnsPolicy: ClusterFirst
              securityContext: {}
              schedulerName: default-scheduler
          strategy:
            type: RollingUpdate
            rollingUpdate:
              maxUnavailable: 1
              maxSurge: 1
          revisionHistoryLimit: 3
          progressDeadlineSeconds: 600
        status:
          observedGeneration: 1
          replicas: 1
          updatedReplicas: 1
          readyReplicas: 1
          availableReplicas: 1
          conditions:
            - type: Available
              status: 'True'
              lastUpdateTime: '2020-02-09T09:16:35Z'
              lastTransitionTime: '2020-02-09T09:16:35Z'
              reason: MinimumReplicasAvailable
              message: Deployment has minimum availability.
            - type: Progressing
              status: 'True'
              lastUpdateTime: '2020-02-09T09:16:39Z'
              lastTransitionTime: '2020-02-09T09:16:34Z'
              reason: NewReplicaSetAvailable
              message: >-
                ReplicaSet "frontend-v-fa70afb9b6-5679d86d66" has successfully
                progressed.
      - kind: Service
        apiVersion: v1
        metadata:
          name: frontend
          namespace: rat-or-cat
          selfLink: /api/v1/namespaces/rat-or-cat/services/frontend
          uid: 065f5425-19b3-4faf-b2dc-ac5720574dab
          resourceVersion: '5724957'
          creationTimestamp: '2020-02-09T09:16:34Z'
          labels:
            module: frontend
            service: frontend
          annotations:
            garden.io/generated: 'true'
            garden.io/manifest-hash: 00bd392148496c80446effc344da48842a0e26895dd28c3033972cad98788ba4
            garden.io/version: v-fa70afb9b6
            kubectl.kubernetes.io/last-applied-configuration: >
              {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{"garden.io/generated":"true","garden.io/manifest-hash":"00bd392148496c80446effc344da48842a0e26895dd28c3033972cad98788ba4","garden.io/version":"v-fa70afb9b6"},"labels":{"module":"frontend","service":"frontend"},"name":"frontend","namespace":"rat-or-cat"},"spec":{"ports":[{"name":"http","port":80,"protocol":"TCP","targetPort":80}],"selector":{"garden.io/version":"v-fa70afb9b6","service":"frontend"},"type":"ClusterIP"}}
        spec:
          ports:
            - name: http
              protocol: TCP
              port: 80
              targetPort: 80
          selector:
            garden.io/version: v-fa70afb9b6
            service: frontend
          clusterIP: 10.152.183.21
          type: ClusterIP
          sessionAffinity: None
        status:
          loadBalancer: {}
    workload:
      kind: Deployment
      apiVersion: apps/v1
      metadata:
        name: frontend-v-fa70afb9b6
        annotations:
          garden.io/configured.replicas: '1'
          garden.io/generated: 'true'
          garden.io/version: v-fa70afb9b6
        namespace: rat-or-cat
        labels:
          module: frontend
          service: frontend
          garden.io/version: v-fa70afb9b6
      spec:
        selector:
          matchLabels:
            service: frontend
            garden.io/version: v-fa70afb9b6
        template:
          metadata:
            labels:
              module: frontend
              service: frontend
              garden.io/version: v-fa70afb9b6
          spec:
            containers:
              - name: frontend
                image: 'localhost:32000/rat-or-cat/frontend:v-fa70afb9b6'
                env:
                  - name: POD_NAME
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.name
                  - name: POD_NAMESPACE
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.namespace
                  - name: POD_IP
                    valueFrom:
                      fieldRef:
                        fieldPath: status.podIP
                  - name: POD_SERVICE_ACCOUNT
                    valueFrom:
                      fieldRef:
                        fieldPath: spec.serviceAccountName
                ports:
                  - name: http
                    protocol: TCP
                    containerPort: 80
                resources:
                  requests:
                    cpu: 10m
                    memory: 64Mi
                  limits:
                    cpu: '1'
                    memory: 1Gi
                imagePullPolicy: IfNotPresent
                securityContext:
                  allowPrivilegeEscalation: false
            restartPolicy: Always
            terminationGracePeriodSeconds: 5
            dnsPolicy: ClusterFirst
        replicas: 1
        strategy:
          type: RollingUpdate
          rollingUpdate:
            maxUnavailable: 1
            maxSurge: 1
        revisionHistoryLimit: 3


[2020-02-09T09:18:07.153Z] Error: Error validating module 'frontend' (packages/frontend/garden.yml): key .services[0][ingresses][0][port] must be a string
    at validateSchema (/snapshot/project/garden-service/tmp/dist/build/src/config/validation.js:0)
    at Object.validateWithPath (/snapshot/project/garden-service/tmp/dist/build/src/config/validation.js:0)
    at Object.<anonymous> (/snapshot/project/garden-service/tmp/dist/build/src/resolve-module.js:0)
    at Generator.next (<anonymous>)
    at fulfilled (/snapshot/project/garden-service/tmp/dist/build/src/resolve-module.js:0)
Error Details:
value:
  services:
    - name: frontend
      ports:
        - name: http
          containerPort: 80
      ingresses:
        - path: /
          port: 4200
  build:
    dependencies: []
context: module 'frontend' (packages/frontend/garden.yml)
errorDescription: "key \e[4m.services[0][ingresses][0][port]\e[24m must be a string"
errorDetails:
  - message: "key \e[4m.services[0][ingresses][0][port]\e[24m must be a string"
    path:
      - services
      - 0
      - ingresses
      - 0
      - port
    type: string.base
    context:
      label: 'services[0].ingresses[0].port'
      value: 4200
      key: port

